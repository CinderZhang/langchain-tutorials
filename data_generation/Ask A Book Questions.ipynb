{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d3e92ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5166d759",
   "metadata": {},
   "source": [
    "### Load your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4a2d6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredPDFLoader(\"../data/field-guide-to-data-science.pdf\")\n",
    "# loader = OnlinePDFLoader(\"https://wolfpaulus.com/wp-content/uploads/2017/05/field-guide-to-data-science.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcdac23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\cinde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\cinde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "detectron2 is not installed. Cannot use the hi_res partitioning strategy. Falling back to partitioning with the fast strategy.\n"
     ]
    }
   ],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4fd7c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document(s) in your data\n",
      "There are 200014 characters in your document\n"
     ]
    }
   ],
   "source": [
    "print (f'You have {len(data)} document(s) in your data')\n",
    "print (f'There are {len(data[0].page_content)} characters in your document')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af9b604",
   "metadata": {},
   "source": [
    "### Chunk your data up into smaller documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb3c6f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "879873a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 248 documents\n"
     ]
    }
   ],
   "source": [
    "print (f'Now you have {len(texts)} documents')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838b2843",
   "metadata": {},
   "source": [
    "### Create embeddings of your documents to get ready for semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "373e695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma, Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import pinecone"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6553c324",
   "metadata": {},
   "source": [
    "OPENAI_API_KEY=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\n",
    "TEMPERATURE=0.5\n",
    "USE_AZURE=False\n",
    "\n",
    "### AZURE\n",
    "# cleanup azure env as already moved to `azure.yaml.template`\n",
    "\n",
    "################################################################################\n",
    "### LLM MODELS\n",
    "################################################################################\n",
    "\n",
    "# SMART_LLM_MODEL - Smart language model (Default: gpt-4)\n",
    "# FAST_LLM_MODEL - Fast language model (Default: gpt-3.5-turbo)\n",
    "SMART_LLM_MODEL=gpt-4\n",
    "FAST_LLM_MODEL=gpt-3.5-turbo\n",
    "\n",
    "### LLM MODEL SETTINGS\n",
    "# FAST_TOKEN_LIMIT - Fast token limit for OpenAI (Default: 4000)\n",
    "# SMART_TOKEN_LIMIT - Smart token limit for OpenAI (Default: 8000)\n",
    "# When using --gpt3only this needs to be set to 4000.\n",
    "FAST_TOKEN_LIMIT=4000\n",
    "SMART_TOKEN_LIMIT=8000\n",
    "\n",
    "################################################################################\n",
    "### MEMORY\n",
    "################################################################################\n",
    "\n",
    "### MEMORY_BACKEND - Memory backend type\n",
    "# local - Default\n",
    "# pinecone - Pinecone (if configured)\n",
    "# redis - Redis (if configured)\n",
    "# milvus - Milvus (if configured)\n",
    "MEMORY_BACKEND=local\n",
    "\n",
    "### PINECONE\n",
    "# PINECONE_API_KEY - Pinecone API Key (Example: my-pinecone-api-key)\n",
    "# PINECONE_ENV - Pinecone environment (region) (Example: us-west-2)\n",
    "PINECONE_API_KEY=feee5e99-142b-4eed-8c04-67c33e24d71d\n",
    "PINECONE_ENV=us-east-1-aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e093ef3",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = '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'\n",
    "PINECONE_API_KEY = 'feee5e99-142b-4eed-8c04-67c33e24d71d'\n",
    "PINECONE_API_ENV = 'us-east-1-aws'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e0d1c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0deb2f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize pinecone\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,  # find at app.pinecone.io\n",
    "    environment=PINECONE_API_ENV  # next to api key in console\n",
    ")\n",
    "index_name = \"longtext\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "388988ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = Pinecone.from_texts([t.page_content for t in texts], embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34929595",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are examples of good data science teams?\"\n",
    "docs = docsearch.similarity_search(query, include_metadata=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c35dcd9",
   "metadata": {},
   "source": [
    "### Query those docs to get your answer back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f051337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b9b1c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.2, openai_api_key=OPENAI_API_KEY)\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f67ea7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query = \"What is the collect stage of data maturity?\"\n",
    "query = \"What is the most important data science skills and tools?\"\n",
    "docs = docsearch.similarity_search(query, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3dfd2b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The most important data science skills and tools are curiosity, creativity, focus, attention to detail, and flexibility. Useful tools include feature hashing, wrapper methods, sensitivity analysis, self organizing maps, deduplication, normalization, format conversion, fast Fourier transform (FFT), discrete wavelet transform, and coordinate transform.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485bc94c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
